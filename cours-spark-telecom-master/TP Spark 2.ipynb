{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "# <div style=\"text-align:center;\">TP Spark 2 : notes perso</div>\n",
    "-------------------------------\n",
    "\n",
    "# <div style=\"text-align:center;\">Début du projet et pre-processings</div>\n",
    "\n",
    "## Chargement des données\n",
    "\n",
    "L’ensemble des ressources nécessaires pour les prochaines questions se trouvent dans la documentation de Spark.\n",
    "\n",
    "Chargez le fichier ***train_clean.csv*** dans un *DataFrame*. La première ligne du fichier donne le nom de chaque colonne (aka le header), on veut que cette ligne soit utilisée pour nommer les colonnes du dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.DataFrame\n",
       "df: org.apache.spark.sql.DataFrame = [project_id: string, name: string ... 12 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "val df: DataFrame = spark\n",
    "  .read\n",
    "  .option(\"header\", true) // utilise la première ligne du (des) fichier(s) comme header\n",
    "  .option(\"inferSchema\", \"true\") // pour inférer le type de chaque colonne (Int, String, etc.)\n",
    "  .csv(\"/home/p5hngk/Downloads/GitHub/INF_729---Introduction_au_framework_Hadoop/cours-spark-telecom-master/data/train_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez le nombre de lignes et le nombre de colonnes dans le DataFrame :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes : 108129\n",
      "Nombre de colonnes : 14\n"
     ]
    }
   ],
   "source": [
    "println(s\"Nombre de lignes : ${df.count}\")\n",
    "println(s\"Nombre de colonnes : ${df.columns.length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez un extrait du DataFrame sous forme de tableau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+-------+--------------------+---------------------+-------+--------+----------+----------------+----------+-----------+-------------+------------+\n",
      "|    project_id|                name|                desc|   goal|            keywords|disable_communication|country|currency|  deadline|state_changed_at|created_at|launched_at|backers_count|final_status|\n",
      "+--------------+--------------------+--------------------+-------+--------------------+---------------------+-------+--------+----------+----------------+----------+-----------+-------------+------------+\n",
      "|kkst1451568084| drawing for dollars|I like drawing pi...|   20.0| drawing-for-dollars|                False|     US|     USD|1241333999|      1241334017|1240600507| 1240602723|            3|           1|\n",
      "|kkst1474482071|Sponsor Dereck Bl...|I  Dereck Blackbu...|  300.0|sponsor-dereck-bl...|                False|     US|     USD|1242429000|      1242432018|1240960224| 1240975592|            2|           0|\n",
      "| kkst183622197|       Mr. Squiggles|So I saw darkpony...|   30.0|        mr-squiggles|                False|     US|     USD|1243027560|      1243027818|1242163613| 1242164398|            0|           0|\n",
      "| kkst597742710|Help me write my ...|Do your part to h...|  500.0|help-me-write-my-...|                False|     US|     USD|1243555740|      1243556121|1240963795| 1240966730|           18|           1|\n",
      "|kkst1913131122|Support casting m...|I m nearing compl...| 2000.0|support-casting-m...|                False|     US|     USD|1243769880|      1243770317|1241177914| 1241180541|            1|           0|\n",
      "|kkst1085176748|        daily digest|I m a fledgling v...|  700.0|        daily-digest|                False|     US|     USD|1243815600|      1243816219|1241050799| 1241464468|           14|           0|\n",
      "|kkst1468954715|iGoozex - Free iP...|I am an independe...|  250.0|igoozex-free-ipho...|                False|     US|     USD|1243872000|      1243872028|1241725172| 1241736308|            2|           0|\n",
      "| kkst194050612|Drive A Faster Ca...|Drive A Faster Ca...| 1000.0|drive-a-faster-ca...|                False|     US|     USD|1244088000|      1244088022|1241460541| 1241470291|           32|           1|\n",
      "| kkst708883590|\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...|Opening Friday  J...| 5000.0|lostles-at-tinys-...|                False|     US|     USD|1244264400|      1244264422|1241415164| 1241480901|           44|           0|\n",
      "| kkst890976740|Choose Your Own A...|This project is f...| 3500.0|choose-your-own-a...|                False|     US|     USD|1244946540|      1244946632|1242268157| 1242273460|           18|           0|\n",
      "|kkst2053381363|Anatomy of a Cred...|I am an independe...|30000.0|anatomy-of-a-cred...|                False|     US|     USD|1245026160|      1245026721|1241829376| 1242056094|            7|           0|\n",
      "| kkst918550886|No-bit: An artist...|I want to create ...|  300.0|no-bit-an-artist-...|                False|     US|     USD|1245038400|      1245038428|1242523061| 1242528805|            2|           0|\n",
      "| kkst934689279|Indie Nerd Board ...|pictured here is ...| 1500.0|indie-nerd-board-...|                False|     US|     USD|1245042600|      1245042919|1242364202| 1242369560|           28|           1|\n",
      "| kkst191414809|Icons for your iP...|I make cool icons...|  500.0|awesome-icons-for...|                False|     US|     USD|1245092400|      1245092431|1241034764| 1241039475|           98|           1|\n",
      "| kkst569584443|HAPPY VALLEY: Dex...|I am a profession...|  500.0|help-me-make-my-w...|                False|     US|     USD|1245528660|      1245528920|1242072711| 1242333869|            3|           0|\n",
      "| kkst485555421|       Project Pedal|Project Pedal is ...| 1000.0|       project-pedal|                False|     US|     USD|1245556740|      1245556829|1242682134| 1242690018|           20|           1|\n",
      "|kkst1537563608|Frank Magazine Er...|We are throwing a...|  600.0|frank-magazine-er...|                False|     US|     USD|1245882360|      1245882631|1244579167| 1244742156|           12|           0|\n",
      "|kkst1261713500|  Crossword Puzzles!|I create crosswor...| 1500.0|   crossword-puzzles|                False|     US|     USD|1246354320|      1246355121|1240997554| 1241005923|          163|           1|\n",
      "| kkst910550425|Run, Blago Run! Show|A 3-day pop-up ar...| 3500.0|  run-blago-run-show|                False|     US|     USD|1246420800|      1246420854|1244299453| 1244388012|           54|           0|\n",
      "| kkst139451001|It Might Become a...|We are broke film...| 1000.0|it-might-become-a...|                False|     US|     USD|1246420800|      1246420840|1243272026| 1243616180|           23|           1|\n",
      "+--------------+--------------------+--------------------+-------+--------------------+---------------------+-------+--------+----------+----------------+----------+-----------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez le schéma du DataFrame, à savoir le nom de chaque colonne avec son type :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- project_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      " |-- goal: string (nullable = true)\n",
      " |-- keywords: string (nullable = true)\n",
      " |-- disable_communication: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- deadline: string (nullable = true)\n",
      " |-- state_changed_at: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- launched_at: string (nullable = true)\n",
      " |-- backers_count: integer (nullable = true)\n",
      " |-- final_status: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignez le type *Int* aux colonnes qui vous semblent contenir des entiers :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- project_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      " |-- goal: integer (nullable = true)\n",
      " |-- keywords: string (nullable = true)\n",
      " |-- disable_communication: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- deadline: integer (nullable = true)\n",
      " |-- state_changed_at: integer (nullable = true)\n",
      " |-- created_at: integer (nullable = true)\n",
      " |-- launched_at: integer (nullable = true)\n",
      " |-- backers_count: integer (nullable = true)\n",
      " |-- final_status: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfCasted: org.apache.spark.sql.DataFrame = [project_id: string, name: string ... 12 more fields]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfCasted: DataFrame = df\n",
    "  .withColumn(\"goal\", $\"goal\".cast(\"Int\"))\n",
    "  .withColumn(\"deadline\" , $\"deadline\".cast(\"Int\"))\n",
    "  .withColumn(\"state_changed_at\", $\"state_changed_at\".cast(\"Int\"))\n",
    "  .withColumn(\"created_at\", $\"created_at\".cast(\"Int\"))\n",
    "  .withColumn(\"launched_at\", $\"launched_at\".cast(\"Int\"))\n",
    "  .withColumn(\"backers_count\", $\"backers_count\".cast(\"Int\"))\n",
    "  .withColumn(\"final_status\", $\"final_status\".cast(\"Int\"))\n",
    "\n",
    "dfCasted.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "Certaines opérations sur les colonnes sont déjà implémentées dans Spark, mais il est souvent nécessaire de faire appel à des fonctions plus complexes. Dans ce cas on peut créer des *UDFs (User Defined Functions)* qui permettent d’implémenter de nouvelles opérations sur les colonnes. Voir la partie User Defined Functions du fichier `spark_notes.md` pour comprendre comment ça fonctionne.\n",
    "\n",
    "Affichez une description statistique des colonnes de type *Int* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+-------------------+\n",
      "|summary|             goal|      backers_count|       final_status|\n",
      "+-------+-----------------+-------------------+-------------------+\n",
      "|  count|           107615|             108128|             108128|\n",
      "|   mean|36839.03430748502|  6434187.413250962| 1052360.7834973366|\n",
      "| stddev|974215.3015529736|9.324061726649426E7|3.776049940184165E7|\n",
      "|    min|                0|                  0|                  0|\n",
      "|    max|        100000000|         1430423170|         1428977971|\n",
      "+-------+-----------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCasted\n",
    "  .select(\"goal\", \"backers_count\", \"final_status\")\n",
    "  .describe()\n",
    "  .show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observez les autres colonnes, posez-vous les bonnes questions : quel cleaning faire pour chaque colonne ? Y a-t-il des colonnes inutiles ? Comment traiter les valeurs manquantes ? A-t-on des données dupliquées ? Quelles sont les valeurs de mes colonnes ? Des répartitions intéressantes ? Des \"fuites du futur\" (vous entendrez souvent le terme *data leakage*) ??? Proposez des cleanings à faire sur les données : des `groupBy-count`, des `show`, des `dropDuplicates`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------+\n",
      "|disable_communication| count|\n",
      "+---------------------+------+\n",
      "|                False|107293|\n",
      "|                 True|   322|\n",
      "|               2500.0|     8|\n",
      "|               1000.0|     7|\n",
      "|               5000.0|     6|\n",
      "|              10000.0|     5|\n",
      "|               2000.0|     4|\n",
      "|  The Artist s Pro...|     3|\n",
      "|               8000.0|     3|\n",
      "|               3000.0|     3|\n",
      "|              25000.0|     3|\n",
      "|               7500.0|     3|\n",
      "|              15000.0|     3|\n",
      "|                300.0|     2|\n",
      "|               4000.0|     2|\n",
      "|                500.0|     2|\n",
      "|               5500.0|     2|\n",
      "|              20000.0|     2|\n",
      "| once-in-a-while-e...|     1|\n",
      "| girly-fantasy-rom...|     1|\n",
      "| book-when-life-gi...|     1|\n",
      "| harvest-moon-an-m...|     1|\n",
      "| well-done-the-wel...|     1|\n",
      "| pearl-a-short-unc...|     1|\n",
      "| no-regrets-a-broo...|     1|\n",
      "| fu4-long-live-rea...|     1|\n",
      "| help-life-the-uni...|     1|\n",
      "| wild-river-out-be...|     1|\n",
      "| precious-waters-r...|     1|\n",
      "| everythings-for-s...|     1|\n",
      "| im-the-art-show-d...|     1|\n",
      "|               4600.0|     1|\n",
      "| my-castle-a-bruta...|     1|\n",
      "|  Blog and DVD str...|     1|\n",
      "| a-luv-w2w-enterta...|     1|\n",
      "| ya-kilt-it-brewin...|     1|\n",
      "| the-concepts-rena...|     1|\n",
      "| block-a-tale-of-m...|     1|\n",
      "| no-beard-the-pira...|     1|\n",
      "| booked-illustrate...|     1|\n",
      "| trio-the-first-su...|     1|\n",
      "| tres-marie-step-o...|     1|\n",
      "| hello-world-moder...|     1|\n",
      "| sometimes-sleep-m...|     1|\n",
      "| fore-gone-minneso...|     1|\n",
      "|               1700.0|     1|\n",
      "| chicago-mazes-a-b...|     1|\n",
      "| better-than-yeste...|     1|\n",
      "| going-solo-my-cd-...|     1|\n",
      "| maywood-records-g...|     1|\n",
      "| whispers-of-never...|     1|\n",
      "| all-is-good-then-...|     1|\n",
      "| post-box-cricket-...|     1|\n",
      "| moments-a-graduat...|     1|\n",
      "|              12500.0|     1|\n",
      "| love-over-war-art...|     1|\n",
      "| let-you-fall-a-de...|     1|\n",
      "| tower-of-gopals-n...|     1|\n",
      "| jason-roberts-deb...|     1|\n",
      "| snapshots-moments...|     1|\n",
      "| us-together-send-...|     1|\n",
      "| the-moo-crew-pets...|     1|\n",
      "| you-me-and-sicily...|     1|\n",
      "| ill-fly-away-a-mu...|     1|\n",
      "| ajax-a-novel-tril...|     1|\n",
      "|       whats-up-seven|     1|\n",
      "| the-other-side-on...|     1|\n",
      "| dont-worry-hell-c...|     1|\n",
      "| watch-the-trailer...|     1|\n",
      "|    pants-the-musical|     1|\n",
      "| put-community-rad...|     1|\n",
      "| no-you-cant-yes-i...|     1|\n",
      "| im-you-dickhead-s...|     1|\n",
      "| carpe-diem-hand-p...|     1|\n",
      "| older-than-oceans...|     1|\n",
      "| this-is-national-...|     1|\n",
      "| the-1st-internati...|     1|\n",
      "| death-anxiety-a-n...|     1|\n",
      "| soulchaser-volume...|     1|\n",
      "| launching-chad-ma...|     1|\n",
      "| lord-earth-napalm...|     1|\n",
      "| yep-its-rocket-sc...|     1|\n",
      "| gravestownfeature...|     1|\n",
      "| sex-suffering-and...|     1|\n",
      "| monte-pittmans-ne...|     1|\n",
      "| chris-irvines-deb...|     1|\n",
      "| childrens-book-cd...|     1|\n",
      "| round-a-girl-bull...|     1|\n",
      "| publishing-perfec...|     1|\n",
      "| help-fund-documen...|     1|\n",
      "|              80000.0|     1|\n",
      "| perkiomenville-ch...|     1|\n",
      "| sultana-playing-c...|     1|\n",
      "| wound-a-narrative...|     1|\n",
      "| motorcycle-we-are...|     1|\n",
      "| publishing-a-new-...|     1|\n",
      "| tin-by-pocket-vin...|     1|\n",
      "| operation-sing-in...|     1|\n",
      "| be-a-part-of-clut...|     1|\n",
      "| sick-the-music-vi...|     1|\n",
      "+---------------------+------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCasted.groupBy(\"disable_communication\").count.orderBy($\"count\".desc).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             country|count|\n",
      "+--------------------+-----+\n",
      "|                  US|91545|\n",
      "|                  GB| 8743|\n",
      "|                  CA| 3733|\n",
      "|                  AU| 1877|\n",
      "|                  NL|  702|\n",
      "|               False|  428|\n",
      "|                  NZ|  354|\n",
      "|                  SE|  240|\n",
      "|                  DK|  196|\n",
      "|                  NO|  113|\n",
      "|                  IE|  111|\n",
      "|               999.0|    2|\n",
      "|steve-sabos-comed...|    1|\n",
      "|the-swirly-twirli...|    1|\n",
      "|here-without-art-...|    1|\n",
      "|the-nashville-ses...|    1|\n",
      "|the-next-golden-a...|    1|\n",
      "|seven-zero-eight-...|    1|\n",
      "|if-the-world-was-...|    1|\n",
      "| rofl-metaphor-56-ep|    1|\n",
      "|              2500.0|    1|\n",
      "|dont-trust-your-s...|    1|\n",
      "|up-until-now-reco...|    1|\n",
      "|smile-its-not-tha...|    1|\n",
      "|kuya-ko-my-big-br...|    1|\n",
      "|hannuka-story-the...|    1|\n",
      "|fire-fox-in-radic...|    1|\n",
      "|faith-struggle-vi...|    1|\n",
      "|jack-chaps-dog-de...|    1|\n",
      "|the-most-loved-a-...|    1|\n",
      "|              5000.0|    1|\n",
      "|             70000.0|    1|\n",
      "|sketches-in-time-...|    1|\n",
      "|all-is-good-then-...|    1|\n",
      "|esp-intuition-and...|    1|\n",
      "|                null|    1|\n",
      "|help-me-fund-my-n...|    1|\n",
      "|together-alone-th...|    1|\n",
      "|center-ice-brewin...|    1|\n",
      "|sexy-krazy-raw-an...|    1|\n",
      "|ms-groundhog-ms-b...|    1|\n",
      "|jason-blum-wester...|    1|\n",
      "|A compendium of h...|    1|\n",
      "|meow-meow-maulana...|    1|\n",
      "|bring-mary-mcdono...|    1|\n",
      "|umeos-the-21st-ce...|    1|\n",
      "|home-is-where-the...|    1|\n",
      "|good-job-thanks-a...|    1|\n",
      "|i-speak-fluent-mo...|    1|\n",
      "|Real life stories...|    1|\n",
      "|my-village-my-lob...|    1|\n",
      "|                True|    1|\n",
      "|we-the-network-it...|    1|\n",
      "|in-the-grass-a-sh...|    1|\n",
      "|hard-lick-sports-...|    1|\n",
      "|the-foxhole-an-ac...|    1|\n",
      "|                  DE|    1|\n",
      "|              1500.0|    1|\n",
      "|il-fazzoletto-an-...|    1|\n",
      "|jenny-macdonalds-...|    1|\n",
      "|going-home-what-a...|    1|\n",
      "|luna-the-lone-wol...|    1|\n",
      "|bobby-lynchs-debu...|    1|\n",
      "|noah-clean-prison...|    1|\n",
      "|intimacy-with-tre...|    1|\n",
      "|landslide-erotic-...|    1|\n",
      "|dont-hang-up-on-m...|    1|\n",
      "|way-up-in-vermont...|    1|\n",
      "|dave-afdahl-cliff...|    1|\n",
      "|improve-the-commu...|    1|\n",
      "|joe-neary-from-lo...|    1|\n",
      "|feature-film-some...|    1|\n",
      "|promote-validated...|    1|\n",
      "|the-123-with-jami...|    1|\n",
      "|             20000.0|    1|\n",
      "|undo-undo-undone-...|    1|\n",
      "|majestys-ep-kings...|    1|\n",
      "|ice-will-reveal-a...|    1|\n",
      "|              1000.0|    1|\n",
      "|sexisgoodtv-web-t...|    1|\n",
      "|elf-tears-war-mag...|    1|\n",
      "|the-voice-of-cour...|    1|\n",
      "|the-bowhunter-a-s...|    1|\n",
      "|chadd-thomas-unfi...|    1|\n",
      "|A blend of Melodi...|    1|\n",
      "|mile-high-a-hilar...|    1|\n",
      "|welcome-to-not-mo...|    1|\n",
      "|randys-vision-for...|    1|\n",
      "|nadjah-nicoles-de...|    1|\n",
      "|no-pride-no-shame...|    1|\n",
      "|line-edge-and-for...|    1|\n",
      "| the-aric-audio-mini|    1|\n",
      "|instead-of-sleepi...|    1|\n",
      "|st-francis-mohamm...|    1|\n",
      "|fight-life-boxing...|    1|\n",
      "|1st-solo-cd-girls...|    1|\n",
      "|derek-v-the-journ...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCasted.groupBy(\"country\").count.orderBy($\"count\".desc).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            currency|count|\n",
      "+--------------------+-----+\n",
      "|                 USD|91545|\n",
      "|                 GBP| 8743|\n",
      "|                 CAD| 3733|\n",
      "|                 AUD| 1877|\n",
      "|                 EUR|  814|\n",
      "|                  US|  406|\n",
      "|                 NZD|  354|\n",
      "|                 SEK|  240|\n",
      "|                 DKK|  196|\n",
      "|                 NOK|  113|\n",
      "|               False|   73|\n",
      "|                  GB|   13|\n",
      "|                  AU|    3|\n",
      "|                  CA|    3|\n",
      "|                  NL|    2|\n",
      "|the-artists-proce...|    1|\n",
      "|             77750.0|    1|\n",
      "|                  NZ|    1|\n",
      "|                null|    1|\n",
      "|the-artists-proce...|    1|\n",
      "|                  NO|    1|\n",
      "|flutter-and-there...|    1|\n",
      "|              1750.0|    1|\n",
      "|              6300.0|    1|\n",
      "|the-artists-proce...|    1|\n",
      "|final-day-a-drama...|    1|\n",
      "|the-arrangement-a...|    1|\n",
      "|the-soloist-first...|    1|\n",
      "|jack-the-radio-lo...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCasted.groupBy(\"currency\").count.orderBy($\"count\".desc).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  deadline|\n",
      "+----------+\n",
      "|1254767400|\n",
      "|1263597060|\n",
      "|1274115540|\n",
      "|1274145060|\n",
      "|1280372820|\n",
      "|1281730020|\n",
      "|1281769200|\n",
      "|1283292000|\n",
      "|1286168724|\n",
      "|1287701689|\n",
      "|1288926510|\n",
      "|1289102340|\n",
      "|1290314164|\n",
      "|1290704714|\n",
      "|1291537500|\n",
      "|1292387613|\n",
      "|1292400000|\n",
      "|1293256800|\n",
      "|1297473364|\n",
      "|1297726200|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCasted.select(\"deadline\").dropDuplicates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|state_changed_at|count|\n",
      "+----------------+-----+\n",
      "|            null|   85|\n",
      "|      1414814340|   26|\n",
      "|      1420088342|   20|\n",
      "|      1425185942|   17|\n",
      "|      1401483613|   14|\n",
      "|      1427860741|   13|\n",
      "|      1414800010|   12|\n",
      "|      1401595142|   12|\n",
      "|      1409543941|   11|\n",
      "|      1414817940|   11|\n",
      "|      1372651141|   10|\n",
      "|      1430452741|   10|\n",
      "|      1359694743|   10|\n",
      "|      1417496340|   10|\n",
      "|      1409544011|   10|\n",
      "|      1343793542|   10|\n",
      "|      1425078013|    9|\n",
      "|      1383289142|    9|\n",
      "|      1423976340|    9|\n",
      "|      1349074740|    9|\n",
      "|      1346471944|    9|\n",
      "|      1364788742|    9|\n",
      "|      1343879941|    9|\n",
      "|      1404197943|    9|\n",
      "|      1383278341|    8|\n",
      "|      1412136011|    8|\n",
      "|      1412135943|    8|\n",
      "|      1420091941|    8|\n",
      "|      1409543940|    7|\n",
      "|      1412146741|    7|\n",
      "|      1417409942|    7|\n",
      "|      1378011540|    7|\n",
      "|      1430539144|    7|\n",
      "|      1388552340|    7|\n",
      "|      1296536343|    7|\n",
      "|      1370059144|    7|\n",
      "|      1420088413|    7|\n",
      "|      1362113941|    7|\n",
      "|      1404187140|    7|\n",
      "|      1427871541|    7|\n",
      "|      1414900740|    7|\n",
      "|      1413604740|    7|\n",
      "|      1425272344|    7|\n",
      "|      1398916740|    7|\n",
      "|      1409554741|    7|\n",
      "|      1338523141|    7|\n",
      "|      1430452742|    7|\n",
      "|      1419483615|    6|\n",
      "|      1420002014|    6|\n",
      "|      1350705540|    6|\n",
      "|      1428030017|    6|\n",
      "|      1405483140|    6|\n",
      "|      1388563140|    6|\n",
      "|      1418457543|    6|\n",
      "|      1420099141|    6|\n",
      "|      1426921141|    6|\n",
      "|      1419224343|    6|\n",
      "|      1410148741|    6|\n",
      "|      1351742343|    6|\n",
      "|      1403495940|    6|\n",
      "|      1425193141|    6|\n",
      "|      1406869141|    6|\n",
      "|      1406865540|    6|\n",
      "|      1418439611|    6|\n",
      "|      1428897544|    6|\n",
      "|      1338523140|    6|\n",
      "|      1417845540|    6|\n",
      "|      1431316742|    6|\n",
      "|      1351742342|    6|\n",
      "|      1378007942|    6|\n",
      "|      1344830342|    6|\n",
      "|      1418716740|    6|\n",
      "|      1357027142|    6|\n",
      "|      1425160813|    6|\n",
      "|      1420174743|    6|\n",
      "|      1389589140|    6|\n",
      "|      1427846420|    6|\n",
      "|      1341125940|    6|\n",
      "|      1402286340|    6|\n",
      "|      1418018340|    6|\n",
      "|      1422777542|    6|\n",
      "|      1341460740|    6|\n",
      "|      1338533940|    6|\n",
      "|      1370224834|    6|\n",
      "|      1407556811|    5|\n",
      "|      1426377613|    5|\n",
      "|      1430420412|    5|\n",
      "|      1418705940|    5|\n",
      "|      1401580810|    5|\n",
      "|      1415779140|    5|\n",
      "|      1413849615|    5|\n",
      "|      1385873943|    5|\n",
      "|      1412139541|    5|\n",
      "|      1334635143|    5|\n",
      "|      1373687940|    5|\n",
      "|      1404705540|    5|\n",
      "|      1342853940|    5|\n",
      "|      1425085212|    5|\n",
      "|      1414782012|    5|\n",
      "|      1423987142|    5|\n",
      "+----------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCasted.groupBy(\"state_changed_at\").count.orderBy($\"count\".desc).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|backers_count|count|\n",
      "+-------------+-----+\n",
      "|            0|12773|\n",
      "|            1| 8788|\n",
      "|            2| 5954|\n",
      "|            3| 4202|\n",
      "|            4| 3174|\n",
      "|            5| 2665|\n",
      "|            6| 2242|\n",
      "|            7| 2000|\n",
      "|            8| 1693|\n",
      "|            9| 1453|\n",
      "|           10| 1413|\n",
      "|           11| 1258|\n",
      "|           13| 1221|\n",
      "|           12| 1191|\n",
      "|           14| 1174|\n",
      "|           15| 1084|\n",
      "|           16| 1043|\n",
      "|           18| 1041|\n",
      "|           17| 1005|\n",
      "|           19|  982|\n",
      "|           20|  899|\n",
      "|           21|  873|\n",
      "|           22|  826|\n",
      "|           23|  825|\n",
      "|           24|  813|\n",
      "|           26|  788|\n",
      "|           25|  785|\n",
      "|           27|  742|\n",
      "|           28|  713|\n",
      "|           29|  677|\n",
      "|           34|  668|\n",
      "|           30|  657|\n",
      "|           32|  633|\n",
      "|           33|  610|\n",
      "|           38|  591|\n",
      "|           31|  589|\n",
      "|           35|  580|\n",
      "|           36|  574|\n",
      "|           40|  572|\n",
      "|           37|  562|\n",
      "|           39|  553|\n",
      "|           41|  530|\n",
      "|           42|  501|\n",
      "|           43|  486|\n",
      "|           48|  467|\n",
      "|           46|  461|\n",
      "|           44|  448|\n",
      "|           47|  448|\n",
      "|           45|  441|\n",
      "|           50|  436|\n",
      "|           52|  410|\n",
      "|           53|  407|\n",
      "|           54|  407|\n",
      "|           55|  389|\n",
      "|           51|  388|\n",
      "|           57|  383|\n",
      "|           56|  376|\n",
      "|           49|  369|\n",
      "|           62|  356|\n",
      "|           61|  352|\n",
      "|           58|  342|\n",
      "|           59|  341|\n",
      "|           64|  339|\n",
      "|           63|  336|\n",
      "|           60|  336|\n",
      "|           66|  327|\n",
      "|           68|  326|\n",
      "|           65|  313|\n",
      "|           71|  303|\n",
      "|           72|  303|\n",
      "|           75|  293|\n",
      "|           67|  290|\n",
      "|           76|  283|\n",
      "|           70|  281|\n",
      "|           73|  278|\n",
      "|           69|  277|\n",
      "|           77|  272|\n",
      "|           74|  267|\n",
      "|           79|  267|\n",
      "|           81|  242|\n",
      "|           78|  235|\n",
      "|           87|  230|\n",
      "|           82|  222|\n",
      "|           84|  221|\n",
      "|           86|  211|\n",
      "|           80|  210|\n",
      "|           89|  204|\n",
      "|           92|  200|\n",
      "|           88|  198|\n",
      "|           94|  195|\n",
      "|           83|  194|\n",
      "|           85|  191|\n",
      "|           93|  188|\n",
      "|           98|  186|\n",
      "|           97|  183|\n",
      "|           95|  179|\n",
      "|           90|  177|\n",
      "|           91|  176|\n",
      "|          104|  175|\n",
      "|          103|  170|\n",
      "+-------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCasted.groupBy(\"backers_count\").count.orderBy($\"count\".desc).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|     goal|final_status|\n",
      "+---------+------------+\n",
      "|100000000|           0|\n",
      "|100000000|           0|\n",
      "|100000000|           0|\n",
      "|100000000|           0|\n",
      "|100000000|           0|\n",
      "|100000000|           0|\n",
      "|100000000|           0|\n",
      "| 73000000|           0|\n",
      "| 70000000|           0|\n",
      "| 50000000|           0|\n",
      "| 50000000|           0|\n",
      "| 50000000|           0|\n",
      "| 50000000|           0|\n",
      "| 39023437|           0|\n",
      "| 30000000|           0|\n",
      "| 30000000|           0|\n",
      "| 25000000|           0|\n",
      "| 25000000|           0|\n",
      "| 22000000|           0|\n",
      "| 21474836|           0|\n",
      "| 21474836|           0|\n",
      "| 21000000|           0|\n",
      "| 20000000|           0|\n",
      "| 20000000|           0|\n",
      "| 17400000|           0|\n",
      "| 16250000|           0|\n",
      "| 16000000|           0|\n",
      "| 15000000|           0|\n",
      "| 15000000|           0|\n",
      "| 11000000|           0|\n",
      "+---------+------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCasted.select(\"goal\", \"final_status\").orderBy($\"goal\".desc).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "| goal|final_status|\n",
      "+-----+------------+\n",
      "|   20|           1|\n",
      "|  300|           0|\n",
      "|   30|           0|\n",
      "|  500|           1|\n",
      "| 2000|           0|\n",
      "|  700|           0|\n",
      "|  250|           0|\n",
      "| 1000|           1|\n",
      "| 5000|           0|\n",
      "| 3500|           0|\n",
      "|30000|           0|\n",
      "|  300|           0|\n",
      "| 1500|           1|\n",
      "|  500|           1|\n",
      "|  500|           0|\n",
      "| 1000|           1|\n",
      "|  600|           0|\n",
      "| 1500|           1|\n",
      "| 3500|           0|\n",
      "| 1000|           1|\n",
      "|  365|           1|\n",
      "|  500|           1|\n",
      "|  400|           1|\n",
      "|  100|           1|\n",
      "|  250|           1|\n",
      "| 3000|           1|\n",
      "|  640|           0|\n",
      "| 3500|           1|\n",
      "|  300|           1|\n",
      "| 1000|           1|\n",
      "+-----+------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCasted.select(\"goal\", \"final_status\").show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|             country|            currency|count|\n",
      "+--------------------+--------------------+-----+\n",
      "|                  US|                 USD|91545|\n",
      "|                  GB|                 GBP| 8743|\n",
      "|                  CA|                 CAD| 3733|\n",
      "|                  AU|                 AUD| 1877|\n",
      "|                  NL|                 EUR|  702|\n",
      "|               False|                  US|  405|\n",
      "|                  NZ|                 NZD|  354|\n",
      "|                  SE|                 SEK|  240|\n",
      "|                  DK|                 DKK|  196|\n",
      "|                  NO|                 NOK|  113|\n",
      "|                  IE|                 EUR|  111|\n",
      "|               False|                  GB|   13|\n",
      "|               False|                  CA|    3|\n",
      "|               False|                  AU|    3|\n",
      "|               False|                  NL|    2|\n",
      "|hannuka-story-the...|               False|    1|\n",
      "|promote-validated...|               False|    1|\n",
      "|instead-of-sleepi...|               False|    1|\n",
      "|              1500.0|the-arrangement-a...|    1|\n",
      "|the-foxhole-an-ac...|               False|    1|\n",
      "|hard-lick-sports-...|               False|    1|\n",
      "|jack-chaps-dog-de...|               False|    1|\n",
      "|noah-clean-prison...|               False|    1|\n",
      "|sketches-in-time-...|               False|    1|\n",
      "|il-fazzoletto-an-...|               False|    1|\n",
      "|               False|                  NO|    1|\n",
      "|my-village-my-lob...|               False|    1|\n",
      "|the-123-with-jami...|               False|    1|\n",
      "|             20000.0|the-soloist-first...|    1|\n",
      "|faith-struggle-vi...|               False|    1|\n",
      "|kuya-ko-my-big-br...|               False|    1|\n",
      "|elf-tears-war-mag...|               False|    1|\n",
      "|umeos-the-21st-ce...|               False|    1|\n",
      "|esp-intuition-and...|               False|    1|\n",
      "|               999.0|the-artists-proce...|    1|\n",
      "|the-bowhunter-a-s...|               False|    1|\n",
      "|Real life stories...|             77750.0|    1|\n",
      "|landslide-erotic-...|               False|    1|\n",
      "|welcome-to-not-mo...|               False|    1|\n",
      "|mile-high-a-hilar...|               False|    1|\n",
      "|                null|                null|    1|\n",
      "|randys-vision-for...|               False|    1|\n",
      "|home-is-where-the...|               False|    1|\n",
      "|the-next-golden-a...|               False|    1|\n",
      "|fire-fox-in-radic...|               False|    1|\n",
      "|way-up-in-vermont...|               False|    1|\n",
      "|i-speak-fluent-mo...|               False|    1|\n",
      "|               999.0|the-artists-proce...|    1|\n",
      "|the-swirly-twirli...|               False|    1|\n",
      "|improve-the-commu...|               False|    1|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCasted.groupBy(\"country\", \"currency\").count.orderBy($\"count\".desc).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enlevez la colonne *disable_communication*. Cette colonne est très largement majoritairement à *false*, il n'y a que 322 *true* (négligeable), le reste est non-identifié :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [project_id: string, name: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2: DataFrame = dfCasted.drop(\"disable_communication\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les fuites du futur\n",
    "\n",
    "Dans les datasets construits a posteriori des évènements, il arrive que des données ne pouvant être connues qu'après la résolution de chaque évènement soient insérées dans le dataset. On a des fuites depuis le futur ! Par exemple, on a ici le nombre de \"backers\" dans la colonne backers_count. Il s'agit du nombre total de personnes ayant investi dans chaque projet, or ce nombre n'est connu qu'après la fin de la campagne.\n",
    "\n",
    "Il faut savoir repérer et traiter ces données pour plusieurs raisons :\n",
    "\n",
    "* pendant l'entraînement (si on ne les a pas enlevées) elles facilitent le travail du modèle puisqu'elles contiennent des informations directement liées à ce qu'on veut prédire. Par exemple, si `backers_count = 0` on est sûr que la campagne a raté.\n",
    "* au moment d'appliquer notre modèle, les données du futur ne sont pas présentes (puisqu'elles ne sont pas encore connues). On ne peut donc pas les utiliser comme input pour un modèle.\n",
    "\n",
    "\n",
    "Ici, pour enlever les données du futur on retire les colonnes *backers_count* et *state_changed_at* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfNoFutur: org.apache.spark.sql.DataFrame = [project_id: string, name: string ... 9 more fields]\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfNoFutur: DataFrame = df2.drop(\"backers_count\", \"state_changed_at\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colonnes currency et country\n",
    "\n",
    "On pourrait penser que les colonnes *currency* et *country* sont redondantes, auquel cas on pourrait enlever une des colonnes. Mais c'est oublier par exemple que tous les pays de la zone euro ont la même monnaie ! Il faut donc garder les deux colonnes.\n",
    "\n",
    "Il semble y avoir des inversions entre ces deux colonnes et du nettoyage à faire. On remarque en particulier que lorsque `country = \"False\"` le country à l'air d'être dans currency. On le voit avec la commande :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|currency|count|\n",
      "+--------+-----+\n",
      "|      US|  405|\n",
      "|      GB|   13|\n",
      "|      AU|    3|\n",
      "|      CA|    3|\n",
      "|      NL|    2|\n",
      "|      NZ|    1|\n",
      "|      NO|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter($\"country\" === \"False\")\n",
    "  .groupBy(\"currency\")\n",
    "  .count\n",
    "  .orderBy($\"count\".desc)\n",
    "  .show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez deux udfs nommées *udf_country* et *udf_currency* telles que :\n",
    "\n",
    "* ***cleanCountry*** : si `country = \"False\"` prendre la valeur de currency, sinon si country est une chaîne de caractères de taille autre que 2 remplacer par *null*, et sinon laisser la valeur country actuelle. On veut les résultat dans une nouvelle colonne *country2*.\n",
    "* ***cleanCurrency*** : si `currency.length != 3` currency prend la valeur `null`, sinon laisser la valeur currency actuelle. On veut les résultats dans une nouvelle colonne `currency2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleanCountry: (country: String, currency: String)String\n",
       "cleanCurrency: (currency: String)String\n",
       "cleanCountryUdf: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function2>,StringType,Some(List(StringType, StringType)))\n",
       "cleanCurrencyUdf: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,StringType,Some(List(StringType)))\n",
       "dfCountry: org.apache.spark.sql.DataFrame = [project_id: string, name: string ... 9 more fields]\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanCountry(country: String, currency: String): String = {\n",
    "  if (country == \"False\")\n",
    "    currency\n",
    "  else\n",
    "    country\n",
    "}\n",
    "\n",
    "def cleanCurrency(currency: String): String = {\n",
    "  if (currency != null && currency.length != 3)\n",
    "    null\n",
    "  else\n",
    "    currency\n",
    "}\n",
    "\n",
    "val cleanCountryUdf = udf(cleanCountry _)\n",
    "val cleanCurrencyUdf = udf(cleanCurrency _)\n",
    "\n",
    "val dfCountry: DataFrame = dfNoFutur\n",
    "  .withColumn(\"country2\", cleanCountryUdf($\"country\", $\"currency\"))\n",
    "  .withColumn(\"currency2\", cleanCurrencyUdf($\"currency\"))\n",
    "  .drop(\"country\", \"currency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+----+--------------------+-------+--------+----------+----------+-----------+------------+\n",
      "|    project_id|                name|                desc|goal|            keywords|country|currency|  deadline|created_at|launched_at|final_status|\n",
      "+--------------+--------------------+--------------------+----+--------------------+-------+--------+----------+----------+-----------+------------+\n",
      "|kkst1451568084| drawing for dollars|I like drawing pi...|  20| drawing-for-dollars|     US|     USD|1241333999|1240600507| 1240602723|           1|\n",
      "|kkst1474482071|Sponsor Dereck Bl...|I  Dereck Blackbu...| 300|sponsor-dereck-bl...|     US|     USD|1242429000|1240960224| 1240975592|           0|\n",
      "| kkst183622197|       Mr. Squiggles|So I saw darkpony...|  30|        mr-squiggles|     US|     USD|1243027560|1242163613| 1242164398|           0|\n",
      "| kkst597742710|Help me write my ...|Do your part to h...| 500|help-me-write-my-...|     US|     USD|1243555740|1240963795| 1240966730|           1|\n",
      "|kkst1913131122|Support casting m...|I m nearing compl...|2000|support-casting-m...|     US|     USD|1243769880|1241177914| 1241180541|           0|\n",
      "|kkst1085176748|        daily digest|I m a fledgling v...| 700|        daily-digest|     US|     USD|1243815600|1241050799| 1241464468|           0|\n",
      "|kkst1468954715|iGoozex - Free iP...|I am an independe...| 250|igoozex-free-ipho...|     US|     USD|1243872000|1241725172| 1241736308|           0|\n",
      "| kkst194050612|Drive A Faster Ca...|Drive A Faster Ca...|1000|drive-a-faster-ca...|     US|     USD|1244088000|1241460541| 1241470291|           1|\n",
      "| kkst708883590|\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...|Opening Friday  J...|5000|lostles-at-tinys-...|     US|     USD|1244264400|1241415164| 1241480901|           0|\n",
      "| kkst890976740|Choose Your Own A...|This project is f...|3500|choose-your-own-a...|     US|     USD|1244946540|1242268157| 1242273460|           0|\n",
      "+--------------+--------------------+--------------------+----+--------------------+-------+--------+----------+----------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfNoFutur.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également faire ce qu'on vient de faire en utilisant `sql.functions.when` :\n",
    "\n",
    "```scala\n",
    "dfNoFutur\n",
    "  .withColumn(\"country2\", when($\"country\" === \"False\", $\"currency\").otherwise($\"country\"))\n",
    "  .withColumn(\"currency2\", when($\"country\".isNotNull && length($\"currency\") =!= 3, null).otherwise($\"currency\"))\n",
    "  .drop(\"country\", \"currency\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a montré ici l'utilisation d'udfs, mais de façon générale toujours privilégier les fonctions déjà codées dans Spark car elles sont optimisées.\n",
    "\n",
    "Pour une classification, l’équilibrage entre les différentes classes cibles dans les données d’entraînement doit être contrôlé (et éventuellement corrigé). Affichez le nombre d’éléments de chaque classe (colonne ***final_status***). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|final_status|count|\n",
      "+------------+-----+\n",
      "|           0|73266|\n",
      "|           1|34419|\n",
      "|           2|   20|\n",
      "|           3|   19|\n",
      "|           5|   17|\n",
      "|          11|   11|\n",
      "|          14|   10|\n",
      "|          23|   10|\n",
      "|          22|   10|\n",
      "|          18|   10|\n",
      "|           6|    9|\n",
      "|           7|    9|\n",
      "|           9|    8|\n",
      "|           4|    7|\n",
      "|           8|    6|\n",
      "|          21|    6|\n",
      "|          13|    6|\n",
      "|          19|    6|\n",
      "|          17|    5|\n",
      "|          49|    5|\n",
      "|          32|    5|\n",
      "|          52|    4|\n",
      "|          62|    4|\n",
      "|          15|    4|\n",
      "|          75|    4|\n",
      "|          28|    4|\n",
      "|          10|    4|\n",
      "|          31|    4|\n",
      "|          57|    4|\n",
      "|          41|    4|\n",
      "+------------+-----+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCountry.groupBy(\"final_status\").count.orderBy($\"count\".desc).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- project_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      " |-- goal: integer (nullable = true)\n",
      " |-- keywords: string (nullable = true)\n",
      " |-- deadline: integer (nullable = true)\n",
      " |-- created_at: integer (nullable = true)\n",
      " |-- launched_at: integer (nullable = true)\n",
      " |-- final_status: integer (nullable = true)\n",
      " |-- country2: string (nullable = true)\n",
      " |-- currency2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCountry.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conservez uniquement les lignes qui nous intéressent pour le modèle, à savoir lorsque `final_status` vaut 0 (Fail) ou 1 (Success). Les autres valeurs ne sont pas définies et on les enlève. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|final_status|count|\n",
      "+------------+-----+\n",
      "|           0|73266|\n",
      "|           1|34419|\n",
      "+------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfCountry2: org.apache.spark.sql.DataFrame = [project_id: string, name: string ... 9 more fields]\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfCountry2: DataFrame = dfCountry\n",
    "  .filter($\"final_status\" === 0 || $\"final_status\" === 1)\n",
    "\n",
    "dfCountry2.groupBy(\"final_status\").count.orderBy($\"count\".desc).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pourrait toutefois tester en mettant toutes les autres valeurs à 0 en considérant que les campagnes qui ne sont pas un Success sont un Fail. Le code serait :\n",
    "```scala\n",
    "def cleanFinalStatus(final_status: Int): Int = {\n",
    "  if (final_status >== 1)\n",
    "    0\n",
    "  else\n",
    "    final_status\n",
    "}\n",
    "\n",
    "val cleanFinalStatusUdf = udf(cleanFinalStatus _)\n",
    "\n",
    "val dfCountry2: DataFrame = dfCountry\n",
    "  .withColumn(\"final_status2\", cleanFinalStatusUdf($\"final_status\"))\n",
    "  .drop(\"final_status\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajouter et manipuler des colonnes\n",
    "\n",
    "Il est parfois utile d’ajouter des *features* (colonnes dans un DataFrame) pour aider le modèle lors de son apprentissage. Ici nous allons créer de nouvelles features à partir de celles déjà présentes dans les données. Dans certains cas on peut ajouter des features en allant chercher des sources de données supplémentaires.\n",
    "\n",
    "Les dates ne sont pas directement exploitables par un modèle sous leur forme initiale dans nos données : il s’agit de timestamps Unix (nombre de secondes depuis le 1er janvier 1970 0h00 UTC). Nous allons traiter ces données pour en extraire des informations pour aider les modèles. Nous allons, entre autres, nous servir des fonctions liées aux dates de l'objet [functions](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$) :          \n",
    "```scala\n",
    "def from_unixtime(ut: Column): Column\n",
    "\n",
    "Converts the number of seconds from unix epoch (1970-01-01 00:00:00 UTC) to a string representing the timestamp of that moment in the current system time zone in the yyyy-MM-dd HH:mm:ss format.\n",
    "```\n",
    "\n",
    "```scala\n",
    "def datediff(end: Column, start: Column): Column\n",
    "\n",
    "Returns the number of days from start to end.\n",
    "Only considers the date part of the input. For example:\n",
    "dateddiff(\"2018-01-10 00:00:00\", \"2018-01-09 23:59:59\")\n",
    "// returns 1\n",
    "```\n",
    "\n",
    "Nous allons maintenant définir un nouveau *DataFrame* à partir de ***dfCountry2*** sur lequel nous allons effectuer les opérations suivantes :\n",
    "* Ajoutez une colonne ***days_campaign*** qui représente la durée de la campagne en jours (le nombre de jours entre *launched_at* et *deadline*).\n",
    "* Ajoutez une colonne ***hours_prepa*** qui représente le nombre d’heures de préparation de la campagne entre *created_at* et *launched_at*. On pourra arrondir le résultat à 3 chiffres après la virgule.\n",
    "* Supprimez les colonnes *launched_at*, *created_at*, et *deadline*, elles ne sont pas exploitables pour un modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+--------+-----------+----------+\n",
      "|days_campaign|hours_prepa|deadline|launched_at|created_at|\n",
      "+-------------+-----------+--------+-----------+----------+\n",
      "|         null| -16651.746|    null| 1344222924|1404169212|\n",
      "|         null|  -8018.505|    null| 1381313492|1410180112|\n",
      "|         null|   -3927.48|    null| 1357429366|1371568297|\n",
      "|         null|  -3405.279|    null| 1370638345|1382897352|\n",
      "|         null|  -3118.938|    null| 1335298561|1346526738|\n",
      "|         null|   -2447.99|    null| 1408807273|1417620039|\n",
      "|         null|  -2161.731|    null| 1271256372|1279038607|\n",
      "|         null|  -1871.667|    null| 1416696076|1423434079|\n",
      "|         null|  -1656.264|    null| 1335826917|1341789469|\n",
      "|         null|  -1648.251|    null| 1310694245|1316627951|\n",
      "+-------------+-----------+--------+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfCountry3: org.apache.spark.sql.DataFrame = [project_id: string, name: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfCountry3: DataFrame = dfCountry2\n",
    "    .withColumn(\"days_campaign\", datediff(from_unixtime($\"deadline\") , from_unixtime($\"launched_at\")))\n",
    "    .withColumn(\"hours_prepa\", ((($\"launched_at\" - $\"created_at\")/3.6).cast(\"Int\")/1000))\n",
    "\n",
    "dfCountry3.select(\"days_campaign\", \"hours_prepa\", \"deadline\", \"launched_at\", \"created_at\").orderBy($\"hours_prepa\".asc).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir pour nettoyer les données avec une date de lancement inférieure à la date de création. Pour cela, commencer par compter le nombre d'heures de prépa négatives. \n",
    "* Si il n'y en a pas beaucoup, voir pour effacer les valeurs.\n",
    "* Sinon, mettre la valeur *launched_at* identique à *created_at*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
