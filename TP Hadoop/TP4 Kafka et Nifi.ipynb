{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "# <center>TP4 : Kafka et NIFI<center>\n",
    "---------------------\n",
    "\n",
    "Pas besoin de VM pour ce cours, on va travailler directement depuis vos poste telecom. Le\n",
    "TP a été testé depuis une VM debian.\n",
    "\n",
    "## Exercice 1 : Kafka\n",
    "\n",
    "Kafka est un Message Oriented Middleware. Nous allons l’installer et le tester. Nous testerons les api entrantes et sortantes, mais aussi la robustesse de Kafka, en killant certains brokers Kafka pendant les écritures ou la lecture de messages.\n",
    "\n",
    "### a. Installation\n",
    "\n",
    "Dans un premier temps, nous allons procéder à l’installation d’un broker Kafka pour comprendre les notions de consumer et producer. Ensuite nous déploierons un cluster de 3 brokers Kafka sur lesquels nous testerons la robustesse.\n",
    "\n",
    "\n",
    "Pour rappel, nous aurons besoin d’un service Zookeeper pour utiliser le service Kafka. Nous pourrions utiliser le zookeeper présent sur les VMs cloudera. pour des raisons de performance, je conseille d’utiliser directement les machines centos de l’école sur lesquelles nous lancerons Zookeeper et Kafka.\n",
    "\n",
    "* Créer un dossier “kafka” sur le filesystem Linux : \n",
    "```shell\n",
    "mkdir kafka\n",
    "```\n",
    "* Récupérer le package : \n",
    "```shell\n",
    "wget https://www-eu.apache.org/dist/kafka/2.3.0/kafka_2.12-2.3.0.tgz```\n",
    "* Décompresser le package : \n",
    "```shell \n",
    "tar -xzf kafka_2.11-2.0.0.tgz```\n",
    "* Entrer dans le répertoire : \n",
    "```shell\n",
    "cd kafka_2.11-2.0.0```\n",
    "* Démarrez le service Zookeeper embarqué : \n",
    "```shell\n",
    "bin/zookeeper-server-start.sh config/zookeeper.properties```\n",
    "\n",
    "\n",
    "Vous pouvez vérifier les Znodes présents sur Zookeeper avec la cli (**ouvrez un autre terminal**) :\n",
    "* On lance le service \"client\" :\n",
    "```shell\n",
    "bin/zookeeper-shell.sh localhost:2181```\n",
    "* On arrive sur une invite de commande qui nous permet de voir différentes choses, notamment :\n",
    "    + les brokers (Znodes) créés avec leurs ids : \n",
    "    ```shell\n",
    "    ls /brokers/ids```\n",
    "    + les topic créés : \n",
    "    ```shell\n",
    "    ls /brokers/topics```\n",
    "  \n",
    "\n",
    "Une fois que Zookeeper a démarré, **ouvrez un autre terminal** et lancez le serveur Kafka :   \n",
    "```shell\n",
    "bin/kafka-server-start.sh config/server.properties\n",
    "```\n",
    "\n",
    "\n",
    "Notez que cette commande prend en entrée un fichier .properties détaillant la configuration du broker Kafka qui va être lancé. Notez la propriété broker.id, permettant d’identifier les brokers.\n",
    "\n",
    "Parmis les options intéressantes, notez aussi le nombre de partitions par topic par défaut, la durée de rétention des messages dans Kafka par défaut. Ces configurations sont spécifiques aux topics.\n",
    "\n",
    "\n",
    "Vérifiez à nouveau sur *Zookeeper cli* les Znodes créés :    \n",
    "```shell\n",
    "ls /brokers/ids\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### b. Création de topic\n",
    "\n",
    "Le service devrait maintenant tourner. Testez le en créant un premier topic Kafka :   \n",
    "```shell\n",
    "bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic fr.telecom.tpkafka.kafkatopictest\n",
    "```\n",
    "\n",
    "\n",
    "Le message ***“Created topic \"fr.telecom.tpkafka.kafkatopictest\".”*** devrait s’afficher dans les logs du broker. Vous pouvez aussi utiliser la commande ci-dessous pour lister les topics déclarés sur votre cluster Kafka :  \n",
    "```shell\n",
    "bin/kafka-topics.sh --list --zookeeper localhost:2181\n",
    "```\n",
    "\n",
    "\n",
    "Vous retrouvez également ces informations via la *cli Zookeeper*, dans les nouveaux Znodes créés:  \n",
    "```shell\n",
    "ls /brokers/topics\n",
    "```\n",
    "\n",
    "### c. Producer Kafka\n",
    "\n",
    "A présent, testez le producer shell de kafka pour écrire des messages dans le topic :\n",
    "```shell\n",
    "bin/kafka-console-producer.sh --broker-list localhost:9092 --topic fr.telecom.tpkafka.kafkatopictest\n",
    "```\n",
    "Cette commande vous ouvre une session d’écriture vers votre topic Kafka. Ecrivez un premier message, faites entrée pour envoyer le message au topic.\n",
    "\n",
    "\n",
    "### d. Consumer Kafka\n",
    "\n",
    "**Dans un autre terminal**, lancez un consumer via :\n",
    "```shell\n",
    "bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic fr.telecom.tpkafka.kafkatopictest --from-beginning`\n",
    "```\n",
    "Vous devriez voir apparaître les messages que vous avez envoyé depuis votre producer.   \n",
    "Votre consumer possède un offset sur le topic Kafka qui vous permet de récupérer les derniers messages non lus. Cependant, l’option `--from-beginning` vous permet de reparcourir l’ensemble des données disponibles dans le topic, sans se soucier de l’offset.     \n",
    "Ces deux commandes possèdent plusieurs options que vous pouvez afficher en les lançant sans arguments.\n",
    "\n",
    "\n",
    "Tapez quelques messages dans votre producer et regardez les apparaitres dans le consumer.\n",
    "\n",
    "\n",
    "### e. Un cluster multi-broker\n",
    "\n",
    "Pour l’instant nous n’avons utilisé qu’un seul broker. Pour tester le parallélisme et la haute tolérance aux pannes de Kafka nous allons créer un cluster de 3 brokers.      \n",
    "\n",
    "Un broker est définit par un fichier de configuration, dans lequel est spécifié l’id du broker, le port sur lequel le broker écoute, et le dossier dans lequel les données seront écrites.     \n",
    "Afin de spécifier les deux autres brokers, créez deux nouveaux fichiers properties en partant du fichier *server.properties*.\n",
    "```shell\n",
    "cd ~/kafka # bien se placer dans le fichier d'installation de kafka\n",
    "cp config/server.properties config/server-1.properties\n",
    "cp config/server.properties config/server-2.properties\n",
    "```\n",
    "\n",
    "Dans ces deux fichiers, en trouvant les lignes correspondantes, modifiez certaines lignes afin d’avoir :\n",
    "* *config/server-1.properties* :     \n",
    "        broker.id=1      \n",
    "        listeners=PLAINTEXT://:9093     \n",
    "        log.dir=/tmp/kafka-logs-1   \n",
    "* *config/server-2.properties* :    \n",
    "        broker.id=2    \n",
    "        listeners=PLAINTEXT://:9094   \n",
    "        log.dir=/tmp/kafka-logs-2    \n",
    "\n",
    "\n",
    "Un de nos brokers tourne déjà. Nous allons maintenant lancer les deux autres brokers.\n",
    "```shell\n",
    "bin/kafka-server-start.sh config/server-1.properties &\n",
    "bin/kafka-server-start.sh config/server-2.properties &\n",
    "```\n",
    "\n",
    "Créez maintenant un nouveau topic, de 1 partition, avec un facteur de réplication de 3 :\n",
    "```shell\n",
    "bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic fr.telecom.tpkafka.topicreplication\n",
    "```\n",
    "\n",
    "Pour voir la façon dont sont réparties les partitions et les réplicas sur un topic, tapez la commande ci-dessous :\n",
    "```shell\n",
    "bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic fr.telecom.tpkafka.topicreplication\n",
    "``` \n",
    "On doit obtenir une réponse du genre :\n",
    "\n",
    "        Topic:fr.telecom.tpkafka.topicreplication \n",
    "        PartitionCount:1 \n",
    "        ReplicationFactor:3\n",
    "        Configs:\n",
    "        Topic: fr.telecom.tpkafka.topicreplication \n",
    "        Partition: 0 Leader: 2 Replicas: 1,2,0\n",
    "        Isr: 1,2,0\n",
    "        \n",
    "Dans mon exemple, ci dessus, on voit que le leader est le broker numéro 2, et qu’il y a 3 réplicas (sur les brokers 1,2 et 0).   \n",
    "\n",
    "**Nous allons maintenant tester la tolérance aux pannes.**\n",
    "\n",
    "Ecrivez quelques messages dans le topic via la commande du producer :\n",
    "```shell\n",
    "bin/kafka-console-producer.sh --broker-list localhost:9092,localhost:9093,localhost:9094 --topic fr.telecom.tpkafka.topicreplication\n",
    "```        \n",
    "Consommez les avec `bin/kafka-console-consumer.sh` (*à compléter*), comme précédemment.\n",
    "\n",
    "**Quittez le consumer**\n",
    "\n",
    "Maintenant killez le broker sur lequel est la partition leader :\n",
    "* vous pouvez quitter le terminal du broker correspondant, en fermant le terminal ou avec `Ctrl+C`\n",
    "* ou utiliser ps faux | grep kafka pour retrouver l’id puis killer le process avec kill -9)\n",
    "\n",
    "Via la commande `describe`, notez que le leader a changé. Avec le producer, envoyez quelques nouveaux messages.    \n",
    "**Relancez le consumer**. Observez que les données sont toujours accessibles.      \n",
    "**Relancez maintenant le broker** que vous avez éteint.\n",
    "\n",
    "#### Créez un script bash qui envoie un message contenant la date et l’heure à la nanoseconde tout les secondes dans le topic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
